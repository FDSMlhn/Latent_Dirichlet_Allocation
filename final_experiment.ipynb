{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data preprocessing \n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "path = os.getcwd()\n",
    "filename = \"ml-20m/ratings.csv\"\n",
    "full_path = os.path.join(path, filename)\n",
    "\n",
    "movie_data = pd.read_csv(full_path,delimiter= \",\")\n",
    "\n",
    "\n",
    "NUM_DATASET=2000\n",
    "#sum(food_data.groupby('userId').count()['movieId']>100)\n",
    "movie_data_100 = movie_data.groupby('userId').agg(['count'])\n",
    "\n",
    "movie_user_id = movie_data_100[(movie_data_100.movieId>100)['count']].sample(NUM_DATASET,random_state=12)\n",
    "\n",
    "\n",
    "selected_movie_data=  movie_data[movie_data['userId'].isin(movie_user_id.index)]\n",
    "\n",
    "id_list = list(movie_title_data.movieId)\n",
    "result_mt = []\n",
    "for user in selected_movie_data.userId.unique():\n",
    "    temp = selected_movie_data[selected_movie_data['userId'].isin([user])]\n",
    "    temp_movie_list = list(temp.movieId)\n",
    "    result_mt.append([temp_movie_list.count(i) for i in id_list])\n",
    "    \n",
    "final_movie_2000 = pd.DataFrame(result_mt,index=selected_movie_data.userId.unique(),columns =movie_title_data.title )\n",
    "final_movie_2000.to_csv('final_movie_2000.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameter tuning for CF\n",
    "from LDA_Gibbs_Sampling import LDA\n",
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "path = os.getcwd()\n",
    "filename = \"final_movie_2000.csv\"\n",
    "full_path = os.path.join(path, filename)\n",
    "\n",
    "movie_data = pd.read_csv(full_path,sep= ',',index_col=False)\n",
    "movie_data = movie_data.drop(movie_data.columns[0],axis=1)\n",
    "#movie_data.head()\n",
    "\n",
    "train, test= train_test_split(movie_data, test_size = 0.1,random_state=3)\n",
    "train_train, train_test= train_test_split(train, test_size = 0.2,random_state=3)\n",
    "\n",
    "start_time =time.time()\n",
    "perplexity_list = []\n",
    "for i in [5,15,25,30,45, 60,100]:\n",
    "    lda = LDA(num_topic=i)\n",
    "    lda.fit(train_train.values)\n",
    "    ##randomly\n",
    "    predict_use_data = train_test.copy()\n",
    "    predict_index = list()\n",
    "    \n",
    "    for num,i in enumerate(train_test.values):\n",
    "        #print(np.nonzero(i)\n",
    "        nonzero_index = i.nonzero()[0]\n",
    "        index = np.random.randint(0, len(nonzero_index),dtype=np.intc)\n",
    "        final_index = nonzero_index[index]\n",
    "        predict_index.append(final_index)\n",
    "        predict_use_data.iloc[num,final_index]= 0\n",
    "    \n",
    "    lda.predict(predict_use_data.values)\n",
    "    perplexity = 0\n",
    "    for num, i in enumerate(predict_index):\n",
    "        perplexity += np.log(lda.results[\"predict_term_distribution\"][num, i])\n",
    "    perplexity = np.exp(-perplexity/(num+1))\n",
    "    perplexity_list.append(perplexity)\n",
    "    present_time=time.time()\n",
    "    print(\"This iteration --- {} seconds ---\".format(round(present_time - start_time,2)))\n",
    "    start_time = present_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simple plot of perplexity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(perplexity_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Evaluation for LDA methods\n",
    "from LDA_Gibbs_Sampling import LDA\n",
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import time \n",
    "import numpy as np\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "path = os.getcwd()\n",
    "filename = \"final_movie_2000.csv\"\n",
    "full_path = os.path.join(path, filename)\n",
    "\n",
    "movie_data = pd.read_csv(full_path,sep= ',',index_col=False)\n",
    "movie_data = movie_data.drop(movie_data.columns[0],axis=1)\n",
    "movie_data.head()\n",
    "\n",
    "train, test= train_test_split(movie_data, test_size = 0.1,random_state=3)\n",
    "#train_train, train_test= train_test_split(train, test_size = 0.2,random_state=)\n",
    "\n",
    "start_time =time.time()\n",
    "perplexity_list = []\n",
    "for i in [15]:\n",
    "    lda = LDA(num_topic=i)\n",
    "    lda.fit(train.values)\n",
    "    ##randomly\n",
    "    predict_use_data = test.copy()\n",
    "    predict_index = list()\n",
    "    size_list = list()\n",
    "    \n",
    "    for num,i in enumerate(test.values):\n",
    "        #print(np.nonzero(i)\n",
    "        nonzero_index = i.nonzero()[0]\n",
    "        size = round(len(i.nonzero()[0])/5)\n",
    "        size_list.append(size) \n",
    "        #index = np.random.randit(0, len(nonzero_index),dtype=np.intc)\n",
    "        #final_index = nonzero_index[index]\n",
    "        #predict_index.append(final_index)\n",
    "        #predict_use_data.iloc[num,final_index]= 0\n",
    "        index =np.random.choice(nonzero_index,replace=False,size=size)\n",
    "        predict_index.append(index)\n",
    "        predict_use_data.iloc[nun,index]= 0\n",
    "        \n",
    "    lda.predict(predict_use_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recall rate computation\n",
    "recall= list()\n",
    "test_user = len(size_list)\n",
    "for top_n in range(0,1000):\n",
    "    recall_rate = 0\n",
    "    for i in range(test_user):\n",
    "        #top_n= 5000\n",
    "        top_n_index = np.argpartition(lda.results['predict_term_distribution'][i],-top_n)[-top_n:]\n",
    "        like_list = set(predict_index[i]).intersection(top_n_index)\n",
    "        recall_rate += len(like_list)/len(predict_index[i])\n",
    "    recall.append(recall_rate/test_user)\n",
    "print(recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
